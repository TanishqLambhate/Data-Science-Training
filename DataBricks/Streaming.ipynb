{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25bab14-de8c-4eb8-8606-7b7b0aaa1115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/sales_csv.csv\",\"dbfs:/Filestore/streaming/input/sales_csv.csv\")\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/customer_datas.json\",\"dbfs:/Filestore/streaming/input/customer_datas.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32ac31be-65ba-43af-9f62-964d4ed3d630",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- CustomerID: string (nullable = true)\n |-- CustomerName: string (nullable = true)\n |-- Region: string (nullable = true)\n |-- SignupDate: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#Initialize SparkSession\n",
    "spark=SparkSession.builder.appName(\"Structured Streaming Example\").getOrCreate()\n",
    "\n",
    "#Define the schema for the csv data\n",
    "sales_schema=\"OrderID INT , OrderDate STRING , CustomerID STRING , PRODUCT STRING, Quantity INT ,Price DOUBLE\"\n",
    "\n",
    "#Read streaming data from csv files\n",
    "df_sales_stream=spark.readStream \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "            .schema(sales_schema) \\\n",
    "                .load(\"dbfs:/Filestore/streaming/input/\")\n",
    "\n",
    "#Define the schema for the json data\n",
    "customer_schema=\"CustomerID STRING, CustomerName STRING, Region STRING , SignupDate STRING\"\n",
    "\n",
    "#Read streaming data from json files\n",
    "df_customers_stream=spark.readStream \\\n",
    "    .format(\"json\") \\\n",
    "        .schema(customer_schema) \\\n",
    "            .load(\"dbfs:/Filestore/streaming/input/\")\n",
    "\n",
    "df_customers_stream.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "431b217d-d53c-4048-ba2f-dfa106646303",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies transformation on sales data...\nAggregated sales data...\nApplies transformation on customer data...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, datediff ,to_timestamp\n",
    "\n",
    "# Transform the sales data: Add a new column for total amount\n",
    "df_sales_transformed=df_sales_stream.select(\n",
    "    col(\"OrderID\"),\n",
    "    to_timestamp(col(\"OrderDate\"),\"yyyy-MM-dd HH:mm:ss\").alias(\"OrderDate\"), #convert OrderDate to TIMESTAMP\n",
    "    col(\"Product\"),\n",
    "    col(\"Quantity\"),\n",
    "    col(\"Price\"),\n",
    "    (col(\"Quantity\")*col(\"Price\")).alias(\"TotalAmount\")\n",
    ")\n",
    "print(\"Applies transformation on sales data...\")\n",
    "\n",
    "#Add watermark to handle late data and perform aggregation\n",
    "df_sales_aggregated=df_sales_transformed.withWatermark(\"OrderDate\", \"1 day\") \\\n",
    "    .groupBy(\"Product\") \\\n",
    "        .agg({\"TotalAmount\":\"sum\"})\n",
    "\n",
    "print(\"Aggregated sales data...\")\n",
    "\n",
    "# Transform the customer data: Add a new column for the number of years since signup\n",
    "df_customer_transformed=df_customers_stream.withColumn(\n",
    "    \"YearsSinceSignup\",\n",
    "    datediff(current_date(),to_timestamp(col(\"SignupDate\"),\"yyyy-MM-dd\")).cast(\"int\")/365\n",
    ")\n",
    "print(\"Applies transformation on customer data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85606c0a-20ad-4379-ab39-9427320206fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started streaming query to write aggregated sales data to console...\nStarted streaming query to write transformed customer data to console...\n"
     ]
    }
   ],
   "source": [
    "#Write the aggregated sales data to console sink for debugging\n",
    "sales_query=df_sales_aggregated.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "        .format(\"console\") \\\n",
    "            .start()\n",
    "\n",
    "print(\"Started streaming query to write aggregated sales data to console...\")\n",
    "\n",
    "# Write the transformed customer data to console sink for debugging\n",
    "customers_query=df_customer_transformed.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "        .format(\"console\") \\\n",
    "            .start()\n",
    "\n",
    "print(\"Started streaming query to write transformed customer data to console...\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Streaming",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
