{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5EdTyf3F8+USuWNREHh1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanishqLambhate/Data-Science-Training/blob/pyspark/Pyspark_day_4_Problem_Statement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akt1I8M7_9eB",
        "outputId": "37272acf-e554-49a0-9d36-13a6deb7ba09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=eedd8729c2340812eab3d9698ae79827aca0fdc114b5de03b0ac32990e1bd543\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Problem Statement: Employee Salary Data Transformation and Analysis\n",
        "\n",
        "# A company has collected a CSV file containing employee data, including names, ages, genders, and salaries. The company’s management is interested in conducting a detailed analysis of their workforce, focusing on the salary structure. They need to implement an ETL (Extract, Transform, Load) pipeline to transform the raw employee data into a more usable format for business decision-making.\n",
        "\n",
        "# **Objective**:\n",
        "# The goal is to build an ETL pipeline using PySpark to transform the raw employee data by applying filtering, creating new salary-related metrics, and calculating salary statistics by gender. After the transformations, the processed data should be saved in an efficient file format (Parquet) for further analysis and reporting.\n",
        "\n",
        "# ### **Task Requirements**:\n",
        "# 1. **Extract**:\n",
        "#    - Load the employee data from a CSV file containing the following columns: `name`, `age`, `gender`, and `salary`.\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample CSV data\n",
        "data = {\n",
        "    \"name\": [\"John\", \"Jane\", \"Mike\", \"Emily\", \"Alex\"],\n",
        "    \"age\": [28, 32, 45, 23, 36],\n",
        "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
        "    \"salary\": [60000, 72000, 84000, 52000, 67000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "csv_file_path = \"/content/sample_people.csv\"\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Confirm the CSV file is created\n",
        "print(f\"CSV file created at: {csv_file_path}\")\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName(\"Create View\").getOrCreate()\n",
        "\n",
        "df_people=spark.read.format(\"csv\").option(\"header\",\"true\").load(csv_file_path)\n",
        "df_people.show()\n",
        "# 2. **Transform**:\n",
        "#    - **Filter**: Only include employees aged 30 and above in the analysis.\n",
        "#    - **Add New Column**: Calculate a 10% bonus on the current salary for each employee and add it as a new column (`salary_with_bonus`).\n",
        "#    - **Aggregation**: Group the employees by gender and compute the average salary for each gender.\n",
        "\n",
        "df_people.createOrReplaceTempView(\"people_temp_view\")\n",
        "\n",
        "#Run an sql query on the view\n",
        "result_temp_view=spark.sql(\"Select * from people_temp_view where age>=30\")\n",
        "\n",
        "result_temp_view.show()\n",
        "\n",
        "result_temp_view=result_temp_view.withColumn(\"salary_with_bonus\",result_temp_view[\"salary\"]*1.1)\n",
        "result_temp_view.show()\n",
        "\n",
        "result_temp_view=result_temp_view.groupBy(\"gender\").avg(\"salary_with_bonus\")\n",
        "result_temp_view.show()\n",
        "\n",
        "\n",
        "# 3. **Load**:\n",
        "#    - Save the transformed data (including the bonus salary) in a Parquet file format for efficient storage and retrieval.\n",
        "#    - Ensure the data can be easily accessed for future analysis or reporting.\n",
        "\n",
        "result_temp_view.write.parquet(\"/content/people_bonus.parquet\")\n",
        "\n",
        "\n",
        "\n",
        "# ### **Key Deliverables**:\n",
        "# 1. A PySpark-based ETL pipeline that performs the following:\n",
        "#    - Loads the raw employee CSV data.\n",
        "#    - Applies filtering, transformations, and aggregations.\n",
        "#    - Saves the transformed data to a Parquet file.\n",
        "# 2. A summary report showing the following:\n",
        "#    - The list of employees aged 30 and above with their original salary and salary with the 10% bonus.\n",
        "#    - The average salary per gender.\n",
        "\n",
        "# ### **Sample Data**:\n",
        "\n",
        "# | name  | age  | gender | salary  |\n",
        "# |-------|------|--------|---------|\n",
        "# | John  | 28   | Male   | 60000   |\n",
        "# | Jane  | 32   | Female | 72000   |\n",
        "# | Mike  | 45   | Male   | 84000   |\n",
        "# | Emily | 23   | Female | 52000   |\n",
        "# | Alex  | 36   | Male   | 67000   |\n",
        "\n",
        "# ### **Expected Output**:\n",
        "\n",
        "# 1. A filtered DataFrame that shows the employees aged 30 and above, with an additional column `salary_with_bonus` (10% bonus added to their salary).\n",
        "\n",
        "# 2. A Parquet file containing the transformed data.\n",
        "\n",
        "# 3. A DataFrame showing the average salary by gender.\n",
        "\n",
        "# ### **Challenges**:\n",
        "# - The raw data may contain employees below the age threshold of 30, who need to be filtered out.\n",
        "# - Calculating new metrics (like salary bonuses) and ensuring data integrity during transformation.\n",
        "# - Efficiently saving the transformed data in a format suitable for large-scale data analytics (e.g., Parquet).\n",
        "\n",
        "# ### **Success Criteria**:\n",
        "# - The company should be able to retrieve the filtered and transformed data with accurate salary information, including the bonus.\n",
        "# - The saved Parquet file should be structured for efficient retrieval and further analysis.\n",
        "# - The aggregated data (average salary by gender) should provide insights into the company's pay structure across genders.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r-7AS0MAKk8",
        "outputId": "eeaca022-da2d-4049-f5e6-f392edb212a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at: /content/sample_people.csv\n",
            "+-----+---+------+------+\n",
            "| name|age|gender|salary|\n",
            "+-----+---+------+------+\n",
            "| John| 28|  Male| 60000|\n",
            "| Jane| 32|Female| 72000|\n",
            "| Mike| 45|  Male| 84000|\n",
            "|Emily| 23|Female| 52000|\n",
            "| Alex| 36|  Male| 67000|\n",
            "+-----+---+------+------+\n",
            "\n",
            "+----+---+------+------+\n",
            "|name|age|gender|salary|\n",
            "+----+---+------+------+\n",
            "|Jane| 32|Female| 72000|\n",
            "|Mike| 45|  Male| 84000|\n",
            "|Alex| 36|  Male| 67000|\n",
            "+----+---+------+------+\n",
            "\n",
            "+----+---+------+------+-----------------+\n",
            "|name|age|gender|salary|salary_with_bonus|\n",
            "+----+---+------+------+-----------------+\n",
            "|Jane| 32|Female| 72000|          79200.0|\n",
            "|Mike| 45|  Male| 84000|92400.00000000001|\n",
            "|Alex| 36|  Male| 67000|          73700.0|\n",
            "+----+---+------+------+-----------------+\n",
            "\n",
            "+------+----------------------+\n",
            "|gender|avg(salary_with_bonus)|\n",
            "+------+----------------------+\n",
            "|Female|               79200.0|\n",
            "|  Male|               83050.0|\n",
            "+------+----------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}