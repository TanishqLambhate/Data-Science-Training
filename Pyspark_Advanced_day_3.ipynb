{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSiTyJAJwZrA/kFcbWIwSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanishqLambhate/Data-Science-Training/blob/pyspark/Pyspark_Advanced_day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vXx1UCQRs_A"
      },
      "outputs": [],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "spark=SparkSession.builder.appName('Advanced DataFrame Operations').getOrCreate()\n",
        "data1=[\n",
        "    (1,'Arjun','IT',75000,'2022-01-15'),\n",
        "    (2,'Vijay','Finance',85000,'2022-03-12'),\n",
        "    (3,'Shalini','IT',90000,'2021-06-30')\n",
        "]\n",
        "data2=[\n",
        "    (4,'Sneha','HR',50000,'2022-05-01'),\n",
        "    (5,'Rahul','Finance',60000,'2022-08-20'),\n",
        "    (6,'Amit','IT',55000,'2021-12-15')\n",
        "]\n",
        "df1=spark.createDataFrame(data1,['emp_id','emp_name','dept','salary','join_date'])\n",
        "df2=spark.createDataFrame(data2,['emp_id','emp_name','dept','salary','join_date'])\n",
        "df1.show()\n",
        "df2.show()\n",
        "\n",
        "#Union of two DataFrames (remove duplicates)\n",
        "union_df=df1.union(df2).dropDuplicates()\n",
        "union_df.show()\n",
        "\n",
        "#Union of two DataFrames (including duplicates)\n",
        "union_all_df=df1.union(df2)\n",
        "union_all_df.show()\n",
        "\n",
        "from pyspark.sql.functions import col,rank\n",
        "\n",
        "#Define a window specification to rank employees by salary within each department\n",
        "window_spec=Window.partitionBy('dept').orderBy(col(\"Salary\").desc())\n",
        "\n",
        "#Add a rank column to the DataFrame\n",
        "ranked_df=union_all_df.withColumn('rank',rank().over(window_spec))\n",
        "ranked_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqBpcmT2R2z3",
        "outputId": "4eeeae32-bb11-4913-9dda-4b3566c69182"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|\n",
            "+------+--------+-------+------+----------+\n",
            "\n",
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|\n",
            "+------+--------+-------+------+----------+\n",
            "\n",
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|\n",
            "+------+--------+-------+------+----------+\n",
            "\n",
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|\n",
            "+------+--------+-------+------+----------+\n",
            "\n",
            "+------+--------+-------+------+----------+----+\n",
            "|emp_id|emp_name|   dept|salary| join_date|rank|\n",
            "+------+--------+-------+------+----------+----+\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|   1|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|   2|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|   1|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|   1|\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|   2|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|   3|\n",
            "+------+--------+-------+------+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a window specification for cumulative sum of salaries within each department\n",
        "window_spec_sum=Window.partitionBy('dept').orderBy('join_date').rowsBetween(Window.unboundedPreceding ,Window.currentRow)\n",
        "\n",
        "from pyspark.sql.functions import sum\n",
        "#Calculate the running total of salries\n",
        "running_total_df=union_all_df.withColumn(\"RunningTotal\",sum(col('salary')).over(window_spec_sum))\n",
        "running_total_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWKpbJV_WQpW",
        "outputId": "6a58e3dc-fec2-4c83-8bad-52304cdcc257"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+------+----------+------------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|RunningTotal|\n",
            "+------+--------+-------+------+----------+------------+\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|       85000|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|      145000|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|       50000|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|       90000|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|      145000|\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|      220000|\n",
            "+------+--------+-------+------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert JoiningDate from string to data type\n",
        "date_converted_df=union_all_df.withColumn(\"join_date\",F.to_date(col(\"join_date\"),\"yyyy-MM-dd\"))\n",
        "date_converted_df.show()\n",
        "\n",
        "#calculate the number of years since joining\n",
        "experience_df=date_converted_df.withColumn(\"years_since_joining\",F.round(F.datediff(F.current_date(),col(\"join_date\"))/365,2))\n",
        "\n",
        "experience_df.show()\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQj_VGMgX4Fg",
        "outputId": "79ede967-e8f9-46d4-cd91-84431d11d746"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|\n",
            "+------+--------+-------+------+----------+\n",
            "\n",
            "+------+--------+-------+------+----------+-------------------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|years_since_joining|\n",
            "+------+--------+-------+------+----------+-------------------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|               2.64|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|               2.48|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|               3.18|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|               2.35|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|               2.04|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|               2.72|\n",
            "+------+--------+-------+------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a new column for next evaluation date(one year after joining)\n",
        "eval_date_df=date_converted_df.withColumn(\"next_evaluation_date\",F.date_add(col(\"join_date\"),365))\n",
        "eval_date_df.show()\n",
        "\n",
        "#Calculate average salary per department\n",
        "avg_salary_df=union_all_df.groupBy(\"dept\").agg(F.round(F.avg(\"salary\"),2).alias(\"avg_salary\"))\n",
        "avg_salary_df.show()\n",
        "\n",
        "#Calculate the total number of employees\n",
        "total_employees_df=union_all_df.agg(F.count(\"*\").alias(\"total_employees\"))\n",
        "total_employees_df.show()\n",
        "\n",
        "#Convert employee names to uppercase\n",
        "upper_name_df=union_all_df.withColumn(\"emp_name\",F.upper(col(\"emp_name\")))\n",
        "upper_name_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJRHtUoZJfX",
        "outputId": "be0a70d9-727c-475e-9e42-e560f905aaa4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+------+----------+--------------------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|next_evaluation_date|\n",
            "+------+--------+-------+------+----------+--------------------+\n",
            "|     1|   Arjun|     IT| 75000|2022-01-15|          2023-01-15|\n",
            "|     2|   Vijay|Finance| 85000|2022-03-12|          2023-03-12|\n",
            "|     3| Shalini|     IT| 90000|2021-06-30|          2022-06-30|\n",
            "|     4|   Sneha|     HR| 50000|2022-05-01|          2023-05-01|\n",
            "|     5|   Rahul|Finance| 60000|2022-08-20|          2023-08-20|\n",
            "|     6|    Amit|     IT| 55000|2021-12-15|          2022-12-15|\n",
            "+------+--------+-------+------+----------+--------------------+\n",
            "\n",
            "+-------+----------+\n",
            "|   dept|avg_salary|\n",
            "+-------+----------+\n",
            "|     IT|  73333.33|\n",
            "|Finance|   72500.0|\n",
            "|     HR|   50000.0|\n",
            "+-------+----------+\n",
            "\n",
            "+---------------+\n",
            "|total_employees|\n",
            "+---------------+\n",
            "|              6|\n",
            "+---------------+\n",
            "\n",
            "+------+--------+-------+------+----------+\n",
            "|emp_id|emp_name|   dept|salary| join_date|\n",
            "+------+--------+-------+------+----------+\n",
            "|     1|   ARJUN|     IT| 75000|2022-01-15|\n",
            "|     2|   VIJAY|Finance| 85000|2022-03-12|\n",
            "|     3| SHALINI|     IT| 90000|2021-06-30|\n",
            "|     4|   SNEHA|     HR| 50000|2022-05-01|\n",
            "|     5|   RAHUL|Finance| 60000|2022-08-20|\n",
            "|     6|    AMIT|     IT| 55000|2021-12-15|\n",
            "+------+--------+-------+------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}